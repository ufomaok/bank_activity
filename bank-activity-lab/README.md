
## Project Intro/Objective
This project utilizes machine learning to engineer pipeline to analyze stock data to support sentiment prediction of stock prices. The project puts the coder into the shoes of a hypothetical data engineer working for a national consumer bank. The goal is to analyze terabytes of stock data to integrate with news headline data to measure how well sentiment analysis can predit stock price patterns. Creating data pipelines and utilizing object-oriented programming (OOP) principles, statistics, and data validation tools contributes to our ability to make data-driven decisions in the real world (in this example, the financial market), which can improve the services we are currently utilizing. 

### Methods Used
* Inferential Statistics
* Machine Learning
* Unit Testing
* Object Oriented Programming
* Data Validation


### Technologies
* Python
* Python Statistics Module


## Project Description
This project involves utilizing machine learning to determine the effectiveness of a stock dataset (spanning over nine weeks). The goal of project is to use data to analyze stock prices, to then predict stock price changes based on news sentiment. To accomplish this feat, this project utilizes OOP principles to create a class ('StockMetrics') that calculates the mean, median, and standard deviation for values. Data validation played a vital role in this project, ensuring that strings were converted into floats/missing data points didn't affect data. 

There are some challenges to consider when  with working with large datasets one of them being the size of dataset. Working with terabytes can be challenging, as it will require machinery and programs that can handle large files. Additionally, it is vital to consistently test data to ensure its accuracy and integrity, as it can be easy to make mistakes (e.g.: when skipping over null values, or converting strings to numbers).
